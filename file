import os
import pandas as pd
import snowflake.connector
import vertica_python
from dotenv import load_dotenv

# --- Configuration & Setup ---
pd.set_option("display.max_rows", None)
pd.set_option("display.max_columns", None)
pd.set_option("display.width", None)
pd.set_option("display.max_colwidth", None)

load_dotenv()
SCHEMA = os.getenv("ER1_SCHEMA", "ER1")
OUTPUT_TABLE = "vertica_snowflake_comparison_DDL"

# --- Helper Functions ---
def normalize(name: str) -> str:
    """Returns a case-insensitive version of a string."""
    return name.casefold()

# --- Connection Functions ---
def connect_to_snowflake():
    """Establishes a connection to the source Snowflake database."""
    print("Connecting to source Snowflake...")
    try:
        conn = snowflake.connector.connect(
            account=os.getenv("URL_SF").split("//")[-1].split(".snowflakecomputing.com")[0],
            user=os.getenv("USER_SDL_SF"),
            private_key_file=os.path.join(os.getenv("DATA_ROOT"), os.getenv("KEYTAB_FILE_SDL_SF")),
            private_key_file_pwd=os.getenv("PASSWORD_SDL_SF"),
            database=os.getenv("DB_SDL_SF_VW"),
            schema=os.getenv("SCHEMA_SDL_SF"),
            warehouse=os.getenv("WAREHOUSE_SDL_SF"),
            role=os.getenv("ROLE_SDL_SF"),
            authenticator='SNOWFLAKE_JWT'
        )
        print("Source Snowflake connected.")
        return conn
    except Exception as e:
        print(f"Error connecting to source Snowflake: {e}")
        raise

def connect_to_vertica():
    """Establishes a connection to the source Vertica database."""
    print("Connecting to source Vertica...")
    try:
        conn = vertica_python.connect(
            host=os.getenv("VERTICA_HOST"),
            port=int(os.getenv("VERTICA_PORT", 5433)),
            user=os.getenv("VERTICA_USER"),
            password=os.getenv("VERTICA_PASSWORD"),
            database=os.getenv("VERTICA_DB"),
            autocommit=True
        )
        print("Source Vertica connected.")
        return conn
    except Exception as e:
        print(f"Error connecting to source Vertica: {e}")
        raise

def connect_to_vertica_dev():
    """Establishes a connection to the destination Vertica DEV database for logging."""
    print("Connecting to destination Vertica (DEV)...")
    try:
        conn = vertica_python.connect(
            host=os.getenv("VERTICA_HOST_DEV"),
            port=int(os.getenv("VERTICA_PORT_DEV", 5433)),
            user=os.getenv("VERTICA_USER_DEV"),
            password=os.getenv("VERTICA_PASSWORD_DEV"),
            database=os.getenv("VERTICA_DB_DEV"),
            autocommit=True
        )
        print("Destination Vertica (DEV) connected.")
        return conn
    except Exception as e:
        print(f"Error connecting to destination Vertica (DEV): {e}")
        raise

# --- Metadata Fetching Functions ---
def get_snowflake_views(conn, schema_name):
    """Fetches view names from Snowflake."""
    with conn.cursor() as cur:
        cur.execute(f"SELECT table_name FROM INFORMATION_SCHEMA.VIEWS WHERE table_schema = %s", (schema_name,))
        return [row[0] for row in cur.fetchall()]

def get_vertica_views(conn, schema_name):
    """Fetches view names from Vertica."""
    with conn.cursor() as cur:
        cur.execute(f"SELECT table_name FROM v_catalog.views WHERE table_schema = %s", (schema_name,))
        return [row[0] for row in cur.fetchall()]

def get_snowflake_columns(conn, view_name, schema_name):
    """Fetches column names for a given view from Snowflake."""
    with conn.cursor() as cur:
        # INFORMATION_SCHEMA.COLUMNS works for views as well
        cur.execute(f"SELECT column_name FROM INFORMATION_SCHEMA.COLUMNS WHERE table_schema = %s AND table_name = %s", (schema_name, view_name))
        return [row[0] for row in cur.fetchall()]

def get_vertica_columns(conn, view_name, schema_name):
    """Fetches column names for a given view from Vertica."""
    with conn.cursor() as cur:
        cur.execute(f"SELECT column_name FROM v_catalog.view_columns WHERE table_schema = %s AND UPPER(table_name) = UPPER(%s)", (schema_name, view_name))
        return [row[0] for row in cur.fetchall()]

# --- Data Writing Function ---
def write_mismatches_to_vertica(conn, mismatches_df):
    """Clears the target table and writes the mismatch DataFrame to Vertica."""
    if mismatches_df.empty:
        print("\nNo mismatches found. Nothing to write.")
        return

    print(f"\nWriting {len(mismatches_df)} mismatches to Vertica table: {OUTPUT_TABLE}...")
    with conn.cursor() as cur:
        try:
            # Clear the table before inserting new data
            print(f"Truncating table {OUTPUT_TABLE}...")
            cur.execute(f"TRUNCATE TABLE {OUTPUT_TABLE};")
            print("Table truncated.")

            # Prepare data for insertion
            insert_query = f"""
                INSERT INTO {OUTPUT_TABLE} (table_name, column_name, objecttype, presentinvertica, presentinsnowflake)
                VALUES (%s, %s, %s, %s, %s)
            """
            data_to_insert = [tuple(row) for row in mismatches_df.to_numpy()]

            # Execute the insert operation
            cur.executemany(insert_query, data_to_insert)
            conn.commit()
            print(f"Successfully inserted {len(data_to_insert)} records.")

        except Exception as e:
            print(f"An error occurred while writing to Vertica: {e}")
            conn.rollback()
            raise

def main():
    sf_conn = None
    vt_conn = None
    vt_dev_conn = None

    try:
        # Establish all database connections
        sf_conn = connect_to_snowflake()
        vt_conn = connect_to_vertica()
        vt_dev_conn = connect_to_vertica_dev()

        # Fetch view lists
        sf_views = get_snowflake_views(sf_conn, SCHEMA)
        vt_views = get_vertica_views(vt_conn, SCHEMA)

        # Create maps from normalized name to original name for case preservation
        sf_view_map = {normalize(t): t for t in sf_views}
        vt_view_map = {normalize(t): t for t in vt_views}

        sf_norm_set = set(sf_view_map.keys())
        vt_norm_set = set(vt_view_map.keys())

        # --- 1. Find View-Level Mismatches ---
        mismatches = []
        views_only_in_sf = sf_norm_set - vt_norm_set
        views_only_in_vt = vt_norm_set - sf_norm_set

        for norm_view in sorted(views_only_in_sf):
            mismatches.append({
                "ViewName": sf_view_map[norm_view],
                "ColumnName": "N/A",
                "ObjectType": "view",
                "PresentInVertica": "N",
                "PresentInSnowflake": "Y",
            })

        for norm_view in sorted(views_only_in_vt):
            mismatches.append({
                "ViewName": vt_view_map[norm_view],
                "ColumnName": "N/A",
                "ObjectType": "view",
                "PresentInVertica": "Y",
                "PresentInSnowflake": "N",
            })

        # --- 2. Find Column-Level Mismatches for Common Views ---
        common_views = sorted(sf_norm_set.intersection(vt_norm_set))
        print(f"\nFound {len(common_views)} common views to compare for column differences...")

        for norm_view in common_views:
            sf_view_name = sf_view_map[norm_view]
            vt_view_name = vt_view_map[norm_view]

            sf_cols = get_snowflake_columns(sf_conn, sf_view_name, SCHEMA)
            vt_cols = get_vertica_columns(vt_conn, vt_view_name, SCHEMA)

            sf_col_map = {normalize(col): col for col in sf_cols}
            vt_col_map = {normalize(col): col for col in vt_cols}

            sf_col_norm_set = set(sf_col_map.keys())
            vt_col_norm_set = set(vt_col_map.keys())

            cols_only_in_sf = sf_col_norm_set - vt_col_norm_set
            cols_only_in_vt = vt_col_norm_set - sf_col_norm_set

            for col_norm in sorted(cols_only_in_sf):
                mismatches.append({
                    "ViewName": sf_view_name,
                    "ColumnName": sf_col_map[col_norm],
                    "ObjectType": "viewcolumn",
                    "PresentInVertica": "N",
                    "PresentInSnowflake": "Y",
                })

            for col_norm in sorted(cols_only_in_vt):
                 mismatches.append({
                    "ViewName": sf_view_name,
                    "ColumnName": vt_col_map[col_norm],
                    "ObjectType": "viewcolumn",
                    "PresentInVertica": "Y",
                    "PresentInSnowflake": "N",
                })

        # --- 3. Process and Write Results ---
        if not mismatches:
            print("\n=== COMPARISON COMPLETE: No mismatches found. ===")
        else:
            final_df = pd.DataFrame(mismatches)
            # Rename the 'ViewName' column to 'table_name' to match the database schema
            final_df.rename(columns={'ViewName': 'table_name'}, inplace=True)
            
            print("\n=== MISMATCHES FOUND ===")
            print(final_df.to_string(index=False))
            
            # Write the results to the Vertica DEV database
            write_mismatches_to_vertica(vt_dev_conn, final_df)

    except Exception as e:
        print(f"\nAn unexpected error occurred in main execution: {e}")
    finally:
        # Close all connections
        if sf_conn:
            sf_conn.close()
        if vt_conn:
            vt_conn.close()
        if vt_dev_conn:
            vt_dev_conn.close()
        print("\nConnections closed.")


if __name__ == "__main__":
    main()
