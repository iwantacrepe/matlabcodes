import os
import pandas as pd
import snowflake.connector
import vertica_python
from dotenv import load_dotenv

load_dotenv()
SCHEMA = os.getenv("ER1_SCHEMA", "ER1")
TABLE = "CLIENT_PROFILE_INFO"
BATCH_SIZE = 10000

def normalize(name: str) -> str:
    return name.casefold()

def compare_sets(a, b):
    sa, sb = set(a), set(b)
    return sorted(sa - sb), sorted(sb - sa), sorted(sa & sb)

def connect_to_snowflake():
    return snowflake.connector.connect(
        account=os.getenv("URL_SF").split("//")[-1].split(".snowflakecomputing.com")[0],
        user=os.getenv("USER_SDL_SF"),
        private_key_file=os.path.join(os.getenv("DATA_ROOT"), os.getenv("KEYTAB_FILE_SDL_SF")),
        private_key_file_pwd=os.getenv("PASSWORD_SDL_SF"),
        database=os.getenv("DB_SDL_SF"),
        schema=os.getenv("SCHEMA_SDL_SF"),
        warehouse=os.getenv("WAREHOUSE_SDL_SF"),
        role=os.getenv("ROLE_SDL_SF"),
        authenticator="SNOWFLAKE_JWT"
    )

def connect_to_vertica():
    return vertica_python.connect(
        host=os.getenv("VERTICA_HOST"),
        port=int(os.getenv("VERTICA_PORT", 5433)),
        user=os.getenv("VERTICA_USER"),
        password=os.getenv("VERTICA_PASSWORD"),
        database=os.getenv("VERTICA_DB"),
        autocommit=True
    )

def get_snowflake_columns(conn, table, schema):
    with conn.cursor() as cur:
        cur.execute("""
            SELECT column_name
            FROM INFORMATION_SCHEMA.COLUMNS
            WHERE table_schema = %s AND table_name = %s
            ORDER BY ordinal_position
        """, (schema, table))
        return [r[0] for r in cur.fetchall()]

def get_vertica_columns(conn, table, schema):
    cur = conn.cursor()
    cur.execute("""
        SELECT column_name
        FROM v_catalog.columns
        WHERE table_schema = %s AND UPPER(table_name) = UPPER(%s)
        ORDER BY ordinal_position
    """, (schema, table))
    cols = [r[0] for r in cur.fetchall()]
    cur.close()
    return cols

def fetch_batches(conn, table, schema, cols, db="sf"):
    order_by = ", ".join(f'"{c}"' if db == "sf" else c for c in cols)
    select_cols = order_by
    if db == "sf":
        base = f'SELECT {select_cols} FROM "{schema}"."{table}"'
    else:
        base = f'SELECT {select_cols} FROM {schema}.{table}'
    qry = f"{base} ORDER BY {order_by} LIMIT %s OFFSET %s"
    offset = 0
    while True:
        cur = conn.cursor()
        cur.execute(qry, (BATCH_SIZE, offset))
        rows = cur.fetchall()
        cur.close()
        if not rows:
            break
        yield pd.DataFrame(rows, columns=cols)
        offset += BATCH_SIZE

def format_value(val):
    return "N/A" if pd.isna(val) else str(val)

def compare_client_profile():
    sf_conn = connect_to_snowflake()
    vt_conn = connect_to_vertica()
    mismatch_records = []
    try:
        sf_cols = get_snowflake_columns(sf_conn, TABLE, SCHEMA)
        vt_cols = get_vertica_columns(vt_conn, TABLE, SCHEMA)

        only_sf, only_vt, common = compare_sets(
            [c.lower() for c in sf_cols],
            [c.lower() for c in vt_cols]
        )
        if only_sf or only_vt:
            raise ValueError(f"Schema mismatch. Snowflake only: {only_sf}, Vertica only: {only_vt}")

        common_cols = [c for c in sf_cols if c.lower() in common]
        sf_batches = fetch_batches(sf_conn, TABLE, SCHEMA, common_cols, db="sf")
        vt_batches = fetch_batches(vt_conn, TABLE, SCHEMA, common_cols, db="vt")

        while True:
            try:
                sf_df = next(sf_batches)
                vt_df = next(vt_batches)
            except StopIteration:
                break

            min_len = min(len(sf_df), len(vt_df))
            for i in range(min_len):
                for col in common_cols:
                    sf_val = sf_df.at[i, col]
                    vt_val = vt_df.at[i, col]
                    if (pd.isna(sf_val) and not pd.isna(vt_val)) or (not pd.isna(sf_val) and pd.isna(vt_val)) or (not pd.isna(sf_val) and not pd.isna(vt_val) and sf_val != vt_val):
                        mismatch_records.append({
                            "tablename": TABLE,
                            "columnname": col,
                            "valuevertica": format_value(vt_val),
                            "valuesnowflake": format_value(sf_val)
                        })

            for i in range(min_len, len(sf_df)):
                row = sf_df.loc[i]
                for col in common_cols:
                    mismatch_records.append({
                        "tablename": TABLE,
                        "columnname": col,
                        "valuevertica": "N/A",
                        "valuesnowflake": f"EXTRA_ROW: {format_value(row[col])}"
                    })

            for i in range(min_len, len(vt_df)):
                row = vt_df.loc[i]
                for col in common_cols:
                    mismatch_records.append({
                        "tablename": TABLE,
                        "columnname": col,
                        "valuevertica": f"EXTRA_ROW: {format_value(row[col])}",
                        "valuesnowflake": "N/A"
                    })

    finally:
        sf_conn.close()
        vt_conn.close()

    if mismatch_records:
        df = pd.DataFrame(mismatch_records)
        df.to_excel("mismatch_report.xlsx", index=False)

if __name__ == "__main__":
    compare_client_profile()