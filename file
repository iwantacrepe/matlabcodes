import os
import pandas as pd
import snowflake.connector
import vertica_python
from openpyxl import load_workbook
from dotenv import load_dotenv

load_dotenv()
SCHEMA = os.getenv("ER1_SCHEMA", "ER1")
BATCH_SIZE = 10000
pd.set_option("display.max_columns", None)

def connect_to_snowflake():
    return snowflake.connector.connect(
        account=os.getenv("URL_SF").split("//")[-1].split(".snowflakecomputing.com")[0],
        user=os.getenv("USER_SDL_SF"),
        private_key_file=os.path.join(os.getenv("DATA_ROOT"), os.getenv("KEYTAB_FILE_SDL_SF")),
        private_key_file_pwd=os.getenv("PASSWORD_SDL_SF"),
        database=os.getenv("DB_SDL_SF"),
        schema=os.getenv("SCHEMA_SDL_SF"),
        warehouse=os.getenv("WAREHOUSE_SDL_SF"),
        role=os.getenv("ROLE_SDL_SF"),
        authenticator="SNOWFLAKE_JWT"
    )

def connect_to_vertica():
    return vertica_python.connect(
        host=os.getenv("VERTICA_HOST"),
        port=int(os.getenv("VERTICA_PORT", 5433)),
        user=os.getenv("VERTICA_USER"),
        password=os.getenv("VERTICA_PASSWORD"),
        database=os.getenv("VERTICA_DB"),
        autocommit=True
    )

def get_snowflake_columns(conn, table):
    with conn.cursor() as cur:
        cur.execute("""
            SELECT column_name FROM INFORMATION_SCHEMA.COLUMNS
            WHERE table_schema = %s AND table_name = %s
            ORDER BY ordinal_position
        """, (SCHEMA, table))
        return [r[0] for r in cur.fetchall()]

def get_vertica_columns(conn, table):
    cur = conn.cursor()
    cur.execute("""
        SELECT column_name FROM v_catalog.columns
        WHERE table_schema = %s AND UPPER(table_name) = UPPER(%s)
        ORDER BY ordinal_position
    """, (SCHEMA, table))
    cols = [r[0] for r in cur.fetchall()]
    cur.close()
    return cols

def fetch_batches(conn, table, cols, dbtype):
    order_by = ", ".join(f'"{col}"' if dbtype == "sf" else col for col in cols)
    select_cols = order_by
    base_query = f'SELECT {select_cols} FROM "{SCHEMA}"."{table}"' if dbtype == "sf" else f'SELECT {select_cols} FROM {SCHEMA}.{table}'
    query = f"{base_query} ORDER BY {order_by} LIMIT %s OFFSET %s"
    offset = 0
    while True:
        cur = conn.cursor()
        cur.execute(query, (BATCH_SIZE, offset))
        rows = cur.fetchall()
        cur.close()
        if not rows:
            break
        yield pd.DataFrame(rows, columns=cols)
        offset += BATCH_SIZE

def format_value(val):
    return "N/A" if pd.isna(val) else str(val)

def compare_tables(table, sf_conn, vt_conn, report_writer):
    print(f"\n[INFO] Comparing table: {table}")
    sf_cols = get_snowflake_columns(sf_conn, table)
    vt_cols = get_vertica_columns(vt_conn, table)

    common_cols = [col for col in sf_cols if col.lower() in {v.lower() for v in vt_cols}]
    if not common_cols:
        print(f"[WARN] No common columns found in table {table}. Skipping.")
        return

    sf_batches = fetch_batches(sf_conn, table, common_cols, "sf")
    vt_batches = fetch_batches(vt_conn, table, common_cols, "vt")
    mismatch_records = []

    while True:
        try:
            sf_df = next(sf_batches)
            vt_df = next(vt_batches)
        except StopIteration:
            break

        min_len = min(len(sf_df), len(vt_df))
        for i in range(min_len):
            for col in common_cols:
                sf_val = sf_df.at[i, col]
                vt_val = vt_df.at[i, col]
                if (pd.isna(sf_val) and not pd.isna(vt_val)) or (not pd.isna(sf_val) and pd.isna(vt_val)) or (sf_val != vt_val):
                    mismatch_records.append({
                        "TableName": table,
                        "ColumnName": col,
                        "ValueInVertica": format_value(vt_val),
                        "ValueInSnowflake": format_value(sf_val),
                    })

        for i in range(min_len, len(sf_df)):
            row = sf_df.loc[i]
            for col in common_cols:
                mismatch_records.append({
                    "TableName": table,
                    "ColumnName": col,
                    "ValueInVertica": "N/A",
                    "ValueInSnowflake": f"EXTRA_ROW: {format_value(row[col])}"
                })

        for i in range(min_len, len(vt_df)):
            row = vt_df.loc[i]
            for col in common_cols:
                mismatch_records.append({
                    "TableName": table,
                    "ColumnName": col,
                    "ValueInVertica": f"EXTRA_ROW: {format_value(row[col])}",
                    "ValueInSnowflake": "N/A"
                })

    if mismatch_records:
        pd.DataFrame(mismatch_records).to_excel(report_writer, sheet_name=table[:31], index=False)
        print(f"[DONE] Mismatches found and written for {table}")
    else:
        print(f"[PASS] No mismatches in table {table}")

def main():
    config = pd.read_excel("test.xlsx")
    if not {"Table Name", "Flag", "Column Name"}.issubset(config.columns):
        raise ValueError("Excel must have 'Table Name', 'Flag', 'Column Name'")

    tables = config["Table Name"].dropna().unique()
    sf_conn = connect_to_snowflake()
    vt_conn = connect_to_vertica()

    with pd.ExcelWriter("final_comparison_report.xlsx", engine='openpyxl') as writer:
        for table in tables:
            compare_tables(table, sf_conn, vt_conn, writer)

    sf_conn.close()
    vt_conn.close()
    print("\nâœ… Report saved to 'final_comparison_report.xlsx'")

if __name__ == "__main__":
    main()