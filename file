import os
import pandas as pd
import snowflake.connector
import vertica_python
from dotenv import load_dotenv

load_dotenv()
SCHEMA = os.getenv("ER1_SCHEMA", "ER1")
START_DATETIME = "2020-10-01 00:00:00"
END_DATETIME = "2025-06-24 23:59:59"

def connect_to_snowflake():
    return snowflake.connector.connect(
        account=os.getenv("URL_SF").split("//")[-1].split(".snowflakecomputing.com")[0],
        user=os.getenv("USER_SDL_SF"),
        private_key_file=os.path.join(os.getenv("DATA_ROOT"), os.getenv("KEYTAB_FILE_SDL_SF")),
        private_key_file_pwd=os.getenv("PASSWORD_SDL_SF"),
        database=os.getenv("DB_SDL_SF"),
        schema=os.getenv("SCHEMA_SDL_SF"),
        warehouse=os.getenv("WAREHOUSE_SDL_SF"),
        role=os.getenv("ROLE_SDL_SF"),
        authenticator="SNOWFLAKE_JWT"
    )

def connect_to_vertica():
    return vertica_python.connect(
        host=os.getenv("VERTICA_HOST"),
        port=int(os.getenv("VERTICA_PORT", 5433)),
        user=os.getenv("VERTICA_USER"),
        password=os.getenv("VERTICA_PASSWORD"),
        database=os.getenv("VERTICA_DB"),
        autocommit=True
    )

def get_columns(conn, table, dbtype="snowflake"):
    if dbtype == "snowflake":
        with conn.cursor() as cur:
            cur.execute("""
                SELECT column_name
                FROM INFORMATION_SCHEMA.COLUMNS
                WHERE table_schema = %s AND table_name = %s
                ORDER BY ordinal_position
            """, (SCHEMA, table))
            return [r[0] for r in cur.fetchall()]
    else:
        cur = conn.cursor()
        cur.execute("""
            SELECT column_name
            FROM v_catalog.columns
            WHERE table_schema = %s AND table_name = %s
            ORDER BY ordinal_position
        """, (SCHEMA, table.lower()))
        cols = [r[0] for r in cur.fetchall()]
        cur.close()
        return cols

def resolve_columns(requested, actual):
    resolved = []
    actual_map = {col.casefold(): col for col in actual}
    for col in requested:
        if col.casefold() not in actual_map:
            raise ValueError(f"Column '{col}' not found in table")
        resolved.append(actual_map[col.casefold()])
    return resolved

def build_outer_join_query(table, columns, keys, filter_col=None):
    select_clause = ", ".join([
        f'a."{col}" AS "{col}_sf", b."{col}" AS "{col}_vt"' for col in columns
    ] + [f'COALESCE(a."{k}", b."{k}") AS "{k}"' for k in keys])

    join_clause = " AND ".join([
        f'a."{k}" = b."{k}"' for k in keys
    ])

    base = f"""
        SELECT {select_clause}
        FROM "{SCHEMA}"."{table}" a
        FULL OUTER JOIN "{SCHEMA}"."{table}" b
        ON {join_clause}
    """

    if filter_col:
        base += f'''
            WHERE COALESCE(a."{filter_col}", b."{filter_col}")
            BETWEEN '{START_DATETIME}' AND '{END_DATETIME}'
        '''
    return base

def format_value(val):
    return "N/A" if pd.isna(val) else str(val)

def compare_rows(df, compare_cols, keys, table):
    mismatches = []
    for _, row in df.iterrows():
        for col in compare_cols:
            val_sf = row.get(f"{col}_sf")
            val_vt = row.get(f"{col}_vt")
            val_sf_str = format_value(val_sf).strip().casefold()
            val_vt_str = format_value(val_vt).strip().casefold()

            if val_sf_str != val_vt_str:
                mismatch = {
                    "TableName": table,
                    "ColumnName": col,
                    "ValueInVertica": format_value(val_vt),
                    "ValueInSnowflake": format_value(val_sf)
                }
                for k in keys:
                    mismatch[k] = format_value(row.get(k))
                mismatches.append(mismatch)
    return mismatches

def compare_table(table, config_df, sf_conn, vt_conn, summary, all_mismatches):
    sub = config_df[config_df["Table Name"].str.casefold() == table.casefold()]
    if (sub["Flag"].str.casefold() == "stage").any():
        summary.append(f"{table}: Skipped (Stage flagged)")
        return

    key_cols = sub[sub["Flag"].str.casefold() == "key"]["Column Name"].tolist()
    exclude_cols = sub[sub["Flag"].str.casefold() == "exclude"]["Column Name"].tolist()
    filter_cols = sub[sub["Flag"].str.casefold() == "filter"]["Column Name"].tolist()
    filter_col = filter_cols[0] if filter_cols else None

    sf_cols = get_columns(sf_conn, table, dbtype="snowflake")
    vt_cols = get_columns(vt_conn, table, dbtype="vertica")

    sf_norm_map = {col.casefold(): col for col in sf_cols}
    vt_norm_map = {col.casefold(): col for col in vt_cols}
    common_norm = set(sf_norm_map.keys()) & set(vt_norm_map.keys())
    common_cols = [sf_norm_map[n] for n in common_norm if n in sf_norm_map and n in vt_norm_map]

    keys = resolve_columns(key_cols, common_cols)
    excludes = resolve_columns(exclude_cols, common_cols) if exclude_cols else []
    filters = resolve_columns(filter_cols, common_cols) if filter_cols else []

    compare_cols = [col for col in common_cols if col not in keys + excludes]

    query = build_outer_join_query(table, compare_cols, keys, filter_col=filter_col)

    with sf_conn.cursor() as sf_cursor:
        sf_cursor.execute(query)
        sf_df = pd.DataFrame(sf_cursor.fetchall(), columns=[desc[0] for desc in sf_cursor.description])

    with vt_conn.cursor() as vt_cursor:
        vt_cursor.execute(query)
        vt_df = pd.DataFrame(vt_cursor.fetchall(), columns=[desc[0] for desc in vt_cursor.description])

    merged = sf_df.merge(vt_df, how='outer')
    mismatches = compare_rows(merged, compare_cols, keys, table)
    all_mismatches.extend(mismatches)

    summary.append(f"{table}: Compared | Keys: {keys} | Excludes: {excludes or 'None'} | Filter: {filters or 'None'}")

def main():
    config = pd.read_excel("test.xlsx")
    required_cols = {"Table Name", "Flag", "Column Name"}
    if not required_cols.issubset(config.columns):
        raise ValueError("Excel file must have columns: Table Name, Flag, Column Name")

    tables = config["Table Name"].dropna().unique()
    sf_conn = connect_to_snowflake()
    vt_conn = connect_to_vertica()
    all_mismatches = []
    summary = []

    try:
        for table in tables:
            compare_table(table, config, sf_conn, vt_conn, summary, all_mismatches)
    finally:
        sf_conn.close()
        vt_conn.close()

    print("\n=== Summary ===")
    for line in summary:
        print(line)

    if all_mismatches:
        df = pd.DataFrame(all_mismatches)
        key_cols = [k for k in df.columns if k not in ["TableName", "ColumnName", "ValueInVertica", "ValueInSnowflake"]]
        final_columns = ["TableName", "ColumnName", "ValueInVertica", "ValueInSnowflake"] + key_cols
        df = df[final_columns]
        df.to_excel("comparison_report.xlsx", index=False)
        print("\nMismatch report saved to comparison_report.xlsx")
    else:
        print("\nNo mismatches found.")

if __name__ == "__main__":
    main()