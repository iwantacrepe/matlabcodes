import os
import pandas as pd
import snowflake.connector
import vertica_python
from dotenv import load_dotenv

load_dotenv()
SCHEMA = os.getenv("ER1_SCHEMA", "ER1")
TABLE = "CLIENT_PROFILE_INFO"
BATCH_SIZE = 10000

pd.set_option("display.max_rows", None)
pd.set_option("display.max_columns", None)
pd.set_option("display.width", None)
pd.set_option("display.max_colwidth", None)

def normalize(name: str) -> str:
    return name.casefold()

def compare_sets(a, b):
    sa, sb = set(a), set(b)
    return sorted(sa - sb), sorted(sb - sa), sorted(sa & sb)

def connect_to_snowflake():
    return snowflake.connector.connect(
        account=os.getenv("URL_SF").split("//")[-1].split(".snowflakecomputing.com")[0],
        user=os.getenv("USER_SDL_SF"),
        private_key_file=os.path.join(os.getenv("DATA_ROOT"), os.getenv("KEYTAB_FILE_SDL_SF")),
        private_key_file_pwd=os.getenv("PASSWORD_SDL_SF"),
        database=os.getenv("DB_SDL_SF"),
        schema=os.getenv("SCHEMA_SDL_SF"),
        warehouse=os.getenv("WAREHOUSE_SDL_SF"),
        role=os.getenv("ROLE_SDL_SF"),
        authenticator="SNOWFLAKE_JWT"
    )

def connect_to_vertica():
    return vertica_python.connect(
        host=os.getenv("VERTICA_HOST"),
        port=int(os.getenv("VERTICA_PORT", 5433)),
        user=os.getenv("VERTICA_USER"),
        password=os.getenv("VERTICA_PASSWORD"),
        database=os.getenv("VERTICA_DB"),
        autocommit=True
    )

def get_snowflake_columns(conn, table, schema):
    with conn.cursor() as cur:
        cur.execute("""
            SELECT column_name
            FROM INFORMATION_SCHEMA.COLUMNS
            WHERE table_schema = %s AND table_name = %s
            ORDER BY ordinal_position
        """, (schema, table))
        return [r[0] for r in cur.fetchall()]

def get_vertica_columns(conn, table, schema):
    cur = conn.cursor()
    cur.execute("""
        SELECT column_name
        FROM v_catalog.columns
        WHERE table_schema = %s AND UPPER(table_name) = UPPER(%s)
        ORDER BY ordinal_position
    """, (schema, table))
    cols = [r[0] for r in cur.fetchall()]
    cur.close()
    return cols

def fetch_batches(conn, table, schema, cols, db="sf"):
    order_by = ", ".join(f'"{c}"' if db == "sf" else c for c in cols)
    select_cols = ", ".join(f'"{c}"' if db == "sf" else c for c in cols)

    if db == "sf":
        base = f'SELECT {select_cols} FROM "{schema}"."{table}"'
    else:
        base = f'SELECT {select_cols} FROM {schema}.{table}'

    qry = f"{base} ORDER BY {order_by} LIMIT %s OFFSET %s"
    offset = 0

    while True:
        cur = conn.cursor()
        cur.execute(qry, (BATCH_SIZE, offset))
        rows = cur.fetchall()
        cur.close()
        if not rows:
            break
        yield pd.DataFrame(rows, columns=cols)
        offset += BATCH_SIZE

def format_value(val):
    return "N/A" if pd.isna(val) else str(val)

def compare_client_profile():
    sf_conn = connect_to_snowflake()
    vt_conn = connect_to_vertica()
    try:
        sf_cols = get_snowflake_columns(sf_conn, TABLE, SCHEMA)
        vt_cols = get_vertica_columns(vt_conn, TABLE, SCHEMA)

        only_sf_c, only_vt_c, common_cols = compare_sets(
            [c.lower() for c in sf_cols],
            [c.lower() for c in vt_cols]
        )

        if only_sf_c or only_vt_c:
            print("❌ Column mismatch found.")
            print("Only in Snowflake:", only_sf_c)
            print("Only in Vertica:", only_vt_c)
            return

        common = [c for c in sf_cols if c.lower() in common_cols]

        sf_batches = fetch_batches(sf_conn, TABLE, SCHEMA, common, db="sf")
        vt_batches = fetch_batches(vt_conn, TABLE, SCHEMA, common, db="vt")

        mismatch_records = []
        batch_num = 0

        while True:
            try:
                sf_df = next(sf_batches)
                vt_df = next(vt_batches)
            except StopIteration:
                break

            min_len = min(len(sf_df), len(vt_df))

            for idx in range(min_len):
                for col in common:
                    sf_val = sf_df.at[idx, col]
                    vt_val = vt_df.at[idx, col]
                    sf_na = pd.isna(sf_val)
                    vt_na = pd.isna(vt_val)

                    if (sf_na and not vt_na) or (not sf_na and vt_na) or (not sf_na and not vt_na and sf_val != vt_val):
                        mismatch_records.append({
                            "TableName": TABLE,
                            "ColumnName": col,
                            "MismatchedValueInVertica": format_value(vt_val),
                            "MismatchedValueInSnowflake": format_value(sf_val)
                        })

            for idx in range(min_len, len(sf_df)):
                row_data = sf_df.loc[idx].to_dict()
                for col in common:
                    mismatch_records.append({
                        "TableName": TABLE,
                        "ColumnName": col,
                        "MismatchedValueInVertica": "N/A",
                        "MismatchedValueInSnowflake": f"EXTRA_ROW: {format_value(row_data.get(col))}"
                    })

            for idx in range(min_len, len(vt_df)):
                row_data = vt_df.loc[idx].to_dict()
                for col in common:
                    mismatch_records.append({
                        "TableName": TABLE,
                        "ColumnName": col,
                        "MismatchedValueInVertica": f"EXTRA_ROW: {format_value(row_data.get(col))}",
                        "MismatchedValueInSnowflake": "N/A"
                    })

            batch_num += 1

        if mismatch_records:
            mismatch_df = pd.DataFrame(mismatch_records)
            print("\n=== FINAL MISMATCH REPORT ===")
            print(mismatch_df.to_string(index=False))
        else:
            print("✅ No mismatches found.")

    finally:
        sf_conn.close()
        vt_conn.close()

if __name__ == "__main__":
    compare_client_profile()