from openpyxl import load_workbook
import os
import pandas as pd
import snowflake.connector
import vertica_python
from dotenv import load_dotenv

# display settings
pd.set_option("display.max_rows", None)
pd.set_option("display.max_columns", None)
pd.set_option("display.width", None)
pd.set_option("display.max_colwidth", None)

load_dotenv()

SCHEMA = os.getenv("ER1_SCHEMA", "ER1")
START_DATETIME = "2020-10-01 00:00:00"
END_DATETIME = "2025-06-24 23:59:59"

def connect_to_snowflake():
    return snowflake.connector.connect(
        account=os.getenv("URL_SF").split("//")[-1].split(".snowflakecomputing.com")[0],
        user=os.getenv("USER_SDL_SF"),
        private_key_file=os.path.join(os.getenv("DATA_ROOT"), os.getenv("KEYTAB_FILE_SDL_SF")),
        private_key_file_pwd=os.getenv("PASSWORD_SDL_SF"),
        database=os.getenv("DB_SDL_SF"),
        schema=os.getenv("SCHEMA_SDL_SF"),
        warehouse=os.getenv("WAREHOUSE_SDL_SF"),
        role=os.getenv("ROLE_SDL_SF"),
        authenticator="SNOWFLAKE_JWT"
    )

def connect_to_vertica():
    return vertica_python.connect(
        host=os.getenv("VERTICA_HOST"),
        port=int(os.getenv("VERTICA_PORT", 5433)),
        user=os.getenv("VERTICA_USER"),
        password=os.getenv("VERTICA_PASSWORD"),
        database=os.getenv("VERTICA_DB"),
        autocommit=True
    )

def get_columns(conn, table, dbtype="snowflake"):
    if dbtype == "snowflake":
        with conn.cursor() as cur:
            cur.execute("""
                SELECT column_name
                  FROM INFORMATION_SCHEMA.COLUMNS
                 WHERE table_schema = %s
                   AND table_name = %s
              ORDER BY ordinal_position
            """, (SCHEMA, table))
            return [r[0] for r in cur.fetchall()]
    else:
        cur = conn.cursor()
        cur.execute("""
            SELECT column_name
              FROM v_catalog.columns
             WHERE table_schema = %s
               AND UPPER(table_name) = UPPER(%s)
          ORDER BY ordinal_position
        """, (SCHEMA, table))
        cols = [r[0] for r in cur.fetchall()]
        cur.close()
        return cols

def resolve_columns(requested, actual, force_upper=False):
    actual_map = {col.casefold(): col for col in actual}
    resolved = []
    for col in requested:
        key = col.casefold()
        if key not in actual_map:
            raise ValueError(f"Column '{col}' not found in table")
        name = actual_map[key]
        resolved.append(name.upper() if force_upper else name)
    return resolved

def fetch_table_df(conn, table, schema, cols, dbtype):
    """
    Pulls the entire table into a DataFrame,
    renaming cols to col_sf or col_vt.
    """
    if dbtype == "sf":
        select = ", ".join(f'"{c}"' for c in cols)
        sql = f'SELECT {select} FROM "{schema}"."{table}"'
        suffix = "_sf"
    else:
        select = ", ".join(cols)
        sql = f"SELECT {select} FROM {schema}.{table}"
        suffix = "_vt"

    cur = conn.cursor()
    cur.execute(sql)
    rows = cur.fetchall()
    cur.close()

    df = pd.DataFrame(rows, columns=cols)
    return df.rename(columns={c: c + suffix for c in cols})

def format_value(val):
    return "N/A" if pd.isna(val) else str(val)

def compare_rows(df, compare_cols, keys, table):
    mismatches = []
    for _, row in df.iterrows():
        for col in compare_cols:
            sf_val = row.get(f"{col}_sf")
            vt_val = row.get(f"{col}_vt")
            sf_str = format_value(sf_val).strip().casefold()
            vt_str = format_value(vt_val).strip().casefold()
            if sf_str != vt_str:
                mismatches.append({
                    "TableName": table,
                    "ColumnName": col,
                    "ValueInVertica": format_value(vt_val),
                    "ValueInSnowflake": format_value(sf_val),
                    "Key": ", ".join(format_value(row.get(k)) for k in keys)
                })
    return mismatches

def compare_table(table, config_df, sf_conn, vt_conn, summary, output_path, first_write):
    sub = config_df[config_df["Table Name"].str.casefold() == table.casefold()]
    if (sub["Flag"].str.casefold() == "stage").any():
        summary.append(f"{table}: Skipped (Stage flagged)")
        return first_write

    key_cols     = sub[sub["Flag"].str.casefold()=="key"]["Column Name"].tolist()
    exclude_cols = sub[sub["Flag"].str.casefold()=="exclude"]["Column Name"].tolist()
    filter_cols  = sub[sub["Flag"].str.casefold()=="filter"]["Column Name"].tolist()
    filter_col   = filter_cols[0] if filter_cols else None

    sf_cols = get_columns(sf_conn, table, dbtype="snowflake")
    vt_cols = get_columns(vt_conn, table, dbtype="vertica")
    sf_map = {c.casefold(): c for c in sf_cols}
    vt_map = {c.casefold(): c for c in vt_cols}
    common_norm = set(sf_map) & set(vt_map)
    common_cols = [sf_map[n] for n in common_norm]

    keys     = resolve_columns(key_cols,     sf_cols + vt_cols, force_upper=True)
    excludes = resolve_columns(exclude_cols, sf_cols + vt_cols, force_upper=True) if exclude_cols else []
    compare_cols = [c for c in common_cols if c not in keys + excludes]

    print(f"\n[INFO] Table: {table}")
    print("  Keys:", keys)
    print("  Compare:", compare_cols)

    # fetch entire tables
    fetch_cols = keys + compare_cols
    sf_df = fetch_table_df(sf_conn, table, SCHEMA, fetch_cols, dbtype="sf")
    vt_df = fetch_table_df(vt_conn, table, SCHEMA, fetch_cols, dbtype="vt")

    # merge
    left_on  = [k + "_sf" for k in keys]
    right_on = [k + "_vt" for k in keys]
    merged = pd.merge(sf_df, vt_df, how="outer", left_on=left_on, right_on=right_on)

    # unify key columns
    for k in keys:
        merged[k] = merged[f"{k}_sf"].fillna(merged[f"{k}_vt"])

    # compare
    mismatches = compare_rows(merged, compare_cols, keys, table)

    if mismatches:
        dfm = pd.DataFrame(mismatches)[["TableName","ColumnName","ValueInVertica","ValueInSnowflake","Key"]]
        if first_write:
            dfm.to_excel(output_path, index=False, engine="openpyxl")
            first_write = False
        else:
            book = load_workbook(output_path)
            with pd.ExcelWriter(output_path, engine="openpyxl", mode="a", if_sheet_exists="overlay") as writer:
                writer.book   = book
                writer.sheets = {ws.title: ws for ws in book.worksheets}
                start = writer.sheets["Sheet1"].max_row
                dfm.to_excel(writer, index=False, header=False, startrow=start)
        summary.append(f"{table}: {len(mismatches)} mismatches")
    else:
        summary.append(f"{table}: No mismatches")

    return first_write

def main():
    config = pd.read_excel("test.xlsx")
    required = {"Table Name", "Flag", "Column Name"}
    if not required.issubset(config.columns):
        raise ValueError("Excel file must have columns: Table Name, Flag, Column Name")

    tables      = config["Table Name"].dropna().unique()
    sf_conn     = connect_to_snowflake()
    vt_conn     = connect_to_vertica()
    summary     = []
    output_path = "comparison_report.xlsx"

    if os.path.exists(output_path):
        os.remove(output_path)
    first_write = True

    try:
        for tbl in tables:
            first_write = compare_table(tbl, config, sf_conn, vt_conn, summary, output_path, first_write)
    finally:
        sf_conn.close()
        vt_conn.close()

    print("\n=== Summary ===")
    for line in summary:
        print(line)

    if os.path.exists(output_path):
        print(f"\nReport saved to {output_path}")
    else:
        print("\nNo mismatches found.")

if __name__ == "__main__":
    main()