import snowflake.connector
import vertica_python
import os
import pandas as pd
from dotenv import load_dotenv
from datetime import datetime

pd.set_option("display.max_rows", None)
pd.set_option("display.max_columns", None)
pd.set_option("display.width", None)
pd.set_option("display.max_colwidth", None)

load_dotenv()

def connect_to_snowflake():
    return snowflake.connector.connect(
        account=os.getenv("URL_SF").split("//")[-1].split(".snowflakecomputing.com")[0],
        user=os.getenv("USER_SDL_SF"),
        private_key_file=os.path.join(os.getenv("DATA_ROOT"), os.getenv("KEYTAB_FILE_SDL_SF")),
        private_key_file_pwd=os.getenv("PASSWORD_SDL_SF"),
        database=os.getenv("DB_SDL_SF"),
        schema=os.getenv("SCHEMA_SDL_SF"),
        warehouse=os.getenv("WAREHOUSE_SDL_SF"),
        role=os.getenv("ROLE_SDL_SF"),
        authenticator='SNOWFLAKE_JWT'
    )

def connect_to_vertica():
    return vertica_python.connect(
        host=os.getenv("VERTICA_HOST"),
        port=5433,
        user=os.getenv("VERTICA_USER"),
        password=os.getenv("VERTICA_PASSWORD"),
        database=os.getenv("VERTICA_DB"),
        autocommit=True
    )

def get_table_list(conn, query):
    cursor = conn.cursor()
    cursor.execute(query)
    tables = [row[0] for row in cursor.fetchall()]
    cursor.close()
    return tables

def get_columns(conn, query):
    cursor = conn.cursor()
    cursor.execute(query)
    columns = [row[0] for row in cursor.fetchall()]
    cursor.close()
    return columns

def get_missing_columns(sf_cols, vt_cols):
    sf_set = set([c.lower() for c in sf_cols])
    vt_set = set([c.lower() for c in vt_cols])
    return sorted(list(sf_set - vt_set))

def main():
    schema_name = "ER1"
    sf_conn = connect_to_snowflake()
    vt_conn = connect_to_vertica()

    try:
        # Get all table names
        sf_tables = get_table_list(sf_conn, f"SELECT TABLE_NAME FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_SCHEMA = '{schema_name}'")
        vt_tables = get_table_list(vt_conn, f"SELECT table_name FROM v_catalog.tables WHERE table_schema = '{schema_name}'")
        vt_table_lookup = {t.lower(): t for t in vt_tables}
        common_tables = [t for t in sf_tables if t.lower() in vt_table_lookup]

        all_rows = []

        for table in common_tables:
            # Get column lists
            sf_cols = get_columns(sf_conn, f"""
                SELECT COLUMN_NAME FROM INFORMATION_SCHEMA.COLUMNS
                WHERE TABLE_NAME = '{table}' AND TABLE_SCHEMA = '{schema_name}'
            """)
            vt_cols = get_columns(vt_conn, f"""
                SELECT column_name FROM v_catalog.columns
                WHERE table_schema = '{schema_name}' AND table_name = '{table.lower()}'
            """)

            # Compare: Show only columns in Snowflake that are missing in Vertica
            missing = get_missing_columns(sf_cols, vt_cols)

            for col in missing:
                all_rows.append({
                    "Table Name": table,
                    "Missing Column in Vertica": col
                })

        # Write to Excel if mismatches found
        if all_rows:
            df = pd.DataFrame(all_rows)
            timestamp = datetime.now().strftime("%Y%m%d_%H%M")
            output_file = f"{schema_name}_missing_columns_only_{timestamp}.xlsx"
            df.to_excel(output_file, sheet_name="MissingOnly", index=False)
            print(f"\n✅ Report saved to: {output_file}")
        else:
            print("\n✅ All columns in Snowflake exist in Vertica. No missing columns found.")

    finally:
        sf_conn.close()
        vt_conn.close()

if __name__ == "__main__":
    main()