import os
import pandas as pd
import numpy as np
import snowflake.connector
import vertica_python
from dotenv import load_dotenv

pd.set_option("display.max_rows", 200)
pd.set_option("display.max_columns", 10)
pd.set_option("display.width", 150)

load_dotenv()
SCHEMA = os.getenv("ER1_SCHEMA", "ER1")
TABLE_NAME = "SNP_KEY_DEVELOPMENTS"
PK_COLUMN = "DEVELOPMENT_ID"
TIMESTAMP_COLUMN = "LASTMODIFIEDDATEUTC"

def connect_to_snowflake():
    conn = snowflake.connector.connect(
        account=os.getenv("URL_SF").split("//")[-1].split(".snowflakecomputing.com")[0],
        user=os.getenv("USER_SDL_SF"),
        private_key_file=os.path.join(os.getenv("DATA_ROOT"), os.getenv("KEYTAB_FILE_SDL_SF")),
        private_key_file_pwd=os.getenv("PASSWORD_SDL_SF"),
        database=os.getenv("DB_SDL_SF_VW"),
        schema=os.getenv("SCHEMA_SDL_SF"),
        warehouse=os.getenv("WAREHOUSE_SDL_SF"),
        role=os.getenv("ROLE_SDL_SF"),
        authenticator='SNOWFLAKE_JWT'
    )
    return conn

def connect_to_vertica():
    conn = vertica_python.connect(
        host=os.getenv("VERTICA_HOST"),
        port=int(os.getenv("VERTICA_PORT", 5433)),
        user=os.getenv("VERTICA_USER"),
        password=os.getenv("VERTICA_PASSWORD"),
        database=os.getenv("VERTICA_DB"),
        autocommit=True,
        session_label='pandas_vertica_fetch'
    )
    return conn

def main():
    sf_conn = None
    vt_conn = None

    try:
        sf_conn = connect_to_snowflake()
        vt_conn = connect_to_vertica()

        query = f"SELECT {PK_COLUMN}, {TIMESTAMP_COLUMN} FROM {SCHEMA}.{TABLE_NAME};"

        sf_df = pd.read_sql(query, sf_conn)
        sf_df.columns = [col.upper() for col in sf_df.columns]
        vt_df = pd.read_sql(query, vt_conn)
        vt_df.columns = [col.upper() for col in vt_df.columns]

        sf_df[TIMESTAMP_COLUMN] = pd.to_datetime(sf_df[TIMESTAMP_COLUMN], errors='coerce')
        vt_df[TIMESTAMP_COLUMN] = pd.to_datetime(vt_df[TIMESTAMP_COLUMN], errors='coerce')

        sf_df[TIMESTAMP_COLUMN] = sf_df[TIMESTAMP_COLUMN].dt.tz_localize(None)
        vt_df[TIMESTAMP_COLUMN] = vt_df[TIMESTAMP_COLUMN].dt.tz_localize(None)

        sf_df.rename(columns={TIMESTAMP_COLUMN: f"{TIMESTAMP_COLUMN}_sf"}, inplace=True)
        vt_df.rename(columns={TIMESTAMP_COLUMN: f"{TIMESTAMP_COLUMN}_vt"}, inplace=True)

        merged_df = pd.merge(
            sf_df,
            vt_df,
            on=PK_COLUMN,
            how="outer"
        )

        sf_col = f'{TIMESTAMP_COLUMN}_sf'
        vt_col = f'{TIMESTAMP_COLUMN}_vt'

        mismatched_values = merged_df[sf_col] != merged_df[vt_col]
        missing_in_sf = merged_df[sf_col].isnull()
        missing_in_vt = merged_df[vt_col].isnull()
        mismatches_df = merged_df[mismatched_values | missing_in_sf | missing_in_vt].copy()

        conditions = [
            (mismatches_df[sf_col].notnull()) & (mismatches_df[vt_col].notnull()),
            mismatches_df[vt_col].isnull(),
            mismatches_df[sf_col].isnull()
        ]
        choices = ['Value Mismatch', 'Missing in Vertica', 'Missing in Snowflake']
        mismatches_df['MismatchReason'] = np.select(conditions, choices, default='Unknown')

        output_cols = [PK_COLUMN, 'MismatchReason', sf_col, vt_col]
        mismatches_df[output_cols].sort_values(by=[PK_COLUMN, 'MismatchReason']).to_excel("timestamp_mismatches.xlsx", index=False)

    except Exception as e:
        print(f"Error: {e}")
    finally:
        if sf_conn: sf_conn.close()
        if vt_conn: vt_conn.close()

if __name__ == "__main__":
    if PK_COLUMN == "YOUR_PRIMARY_KEY":
        print("Update the 'PK_COLUMN' variable before running.")
    else:
        main()