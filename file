import os
import hashlib
import pandas as pd
import snowflake.connector
import vertica_python
from dotenv import load_dotenv

#–– Configuration ––#
load_dotenv()
SCHEMA     = os.getenv("ER1_SCHEMA", "ER1")
TABLE      = "CLIENT_PROFILE_INFO"
BATCH_SIZE = 10000  # tune as needed

pd.set_option("display.max_rows", None)
pd.set_option("display.max_columns", None)
pd.set_option("display.width", None)
pd.set_option("display.max_colwidth", None)

#–– Helpers ––#
def normalize(name: str) -> str:
    return name.casefold()

def compare_sets(a, b):
    sa, sb = set(a), set(b)
    return sorted(sa - sb), sorted(sb - sa), sorted(sa & sb)

def generate_row_hash(row: pd.Series, cols: list) -> str:
    # join with null marker for None
    values = [(str(row[c]) if pd.notna(row[c]) else "<NULL>") for c in cols]
    return hashlib.md5("|".join(values).encode("utf-8")).hexdigest()

#–– Connections ––#
def connect_to_snowflake():
    return snowflake.connector.connect(
        account     = os.getenv("URL_SF").split("//")[-1].split(".snowflakecomputing.com")[0],
        user        = os.getenv("USER_SDL_SF"),
        private_key_file     = os.path.join(os.getenv("DATA_ROOT"), os.getenv("KEYTAB_FILE_SDL_SF")),
        private_key_file_pwd = os.getenv("PASSWORD_SDL_SF"),
        database    = os.getenv("DB_SDL_SF"),
        schema      = os.getenv("SCHEMA_SDL_SF"),
        warehouse   = os.getenv("WAREHOUSE_SDL_SF"),
        role        = os.getenv("ROLE_SDL_SF"),
        authenticator = "SNOWFLAKE_JWT"
    )

def connect_to_vertica():
    return vertica_python.connect(
        host       = os.getenv("VERTICA_HOST"),
        port       = int(os.getenv("VERTICA_PORT", 5433)),
        user       = os.getenv("VERTICA_USER"),
        password   = os.getenv("VERTICA_PASSWORD"),
        database   = os.getenv("VERTICA_DB"),
        autocommit = True
    )

#–– Schema Discovery ––#
def get_snowflake_columns(conn, table, schema):
    with conn.cursor() as cur:
        cur.execute("""
            SELECT column_name
              FROM INFORMATION_SCHEMA.COLUMNS
             WHERE table_schema = %s
               AND table_name   = %s
             ORDER BY ordinal_position
        """, (schema, table))
        return [r[0] for r in cur.fetchall()]

def get_vertica_columns(conn, table, schema):
    cur = conn.cursor()
    cur.execute("""
        SELECT column_name
          FROM v_catalog.columns
         WHERE table_schema = %s
           AND UPPER(table_name) = UPPER(%s)
         ORDER BY ordinal_position
    """, (schema, table))
    cols = [r[0] for r in cur.fetchall()]
    cur.close()
    return cols

#–– Batch Fetch ––#
def fetch_batches(conn, table, schema, cols, db="sf"):
    order_by    = ", ".join(f'"{c}"' if db=="sf" else c for c in cols)
    select_cols = ", ".join(f'"{c}"' if db=="sf" else c for c in cols)

    if db == "sf":
        base = f'SELECT {select_cols} FROM "{schema}"."{table}"'
    else:
        base = f'SELECT {select_cols} FROM {schema}.{table}'

    query = f"{base} ORDER BY {order_by} LIMIT %s OFFSET %s"
    offset = 0

    while True:
        cur = conn.cursor()
        cur.execute(query, (BATCH_SIZE, offset))
        rows = cur.fetchall()
        cur.close()
        if not rows:
            break
        yield pd.DataFrame(rows, columns=cols)
        offset += BATCH_SIZE

#–– Main Comparison ––#
def compare_client_profile():
    sf_conn = connect_to_snowflake()
    vt_conn = connect_to_vertica()
    try:
        print(f"\n=== Comparing table: {TABLE} ===")

        # Column-level
        sf_cols = get_snowflake_columns(sf_conn, TABLE, SCHEMA)
        vt_cols = get_vertica_columns(vt_conn, TABLE, SCHEMA)

        only_sf_c, only_vt_c, common_cols = compare_sets(
            [c.lower() for c in sf_cols],
            [c.lower() for c in vt_cols]
        )

        print("\n-- Column Comparison --")
        if only_sf_c:
            print(f"Columns only in Snowflake: {only_sf_c}")
        if only_vt_c:
            print(f"Columns only in Vertica  : {only_vt_c}")
        if not only_sf_c and not only_vt_c:
            print("✅ Columns match case-insensitively.")
        else:
            # if columns differ, stop here
            return

        # recover original-case column list in Snowflake order
        common = [c for c in sf_cols if c.lower() in common_cols]

        # Row-level
        print(f"\n-- Row-wise Comparison on columns: {common} --")
        sf_batches = fetch_batches(sf_conn, TABLE, SCHEMA, common, db="sf")
        vt_batches = fetch_batches(vt_conn, TABLE, SCHEMA, common, db="vt")

        batch_num = 0
        total_mismatches = 0

        while True:
            try:
                sf_df = next(sf_batches)
                vt_df = next(vt_batches)
            except StopIteration:
                break

            # if counts differ in this batch
            if len(sf_df) != len(vt_df):
                print(f"❗ Batch {batch_num}: row count mismatch (SF={len(sf_df)}, VT={len(vt_df)})")
                total_mismatches += abs(len(sf_df) - len(vt_df))
                break

            # compare row hashes
            sf_hash = sf_df.apply(lambda r: generate_row_hash(r, common), axis=1)
            vt_hash = vt_df.apply(lambda r: generate_row_hash(r, common), axis=1)

            diffs = sf_hash != vt_hash
            if diffs.any():
                for idx in diffs[diffs].index:
                    total_mismatches += 1
                    print(f"\n>> Mismatch in batch {batch_num}, row {idx}:")
                    print(" Snowflake Row:", sf_df.loc[idx].to_dict())
                    print(" Vertica   Row:", vt_df.loc[idx].to_dict())

            batch_num += 1

        if total_mismatches == 0:
            print("\n✅ No row-level mismatches found.")
        else:
            print(f"\n❌ Total mismatches: {total_mismatches}")

    finally:
        sf_conn.close()
        vt_conn.close()
        print("\nConnections closed.")

if __name__ == "__main__":
    compare_client_profile()